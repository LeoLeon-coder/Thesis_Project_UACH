{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Beehive Audio → NumPy Feature Builder (Log-Mel first, MFCC optional)\n",
        "\n",
        "This notebook cleans WAV files, segments them, extracts **log-Mel** (default) or **MFCC(+Δ,+ΔΔ)** features,\n",
        "and exports NumPy arrays (`.npy`) into a separate directory for CNN training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "# If you need to install, uncomment:\n",
        "# !pip install librosa soundfile scipy scikit-learn numpy\n",
        "\n",
        "import os\n",
        "from pathlib import Path\n",
        "import json\n",
        "import random\n",
        "\n",
        "import numpy as np\n",
        "import librosa\n",
        "import soundfile as sf\n",
        "from scipy.signal import butter, sosfiltfilt\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6f4df48f",
      "metadata": {},
      "source": [
        "## Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- Paths ---\n",
        "# Set your dataset path; it should contain class subfolders, e.g.:\n",
        "# data_bees/\n",
        "#   ├─ queen/*.wav\n",
        "#   └─ no_queen/*.wav\n",
        "# --- Paths ---\n",
        "# Folder containing all WAV files (not separated by class)\n",
        "DATA_DIR = Path(r\"C:\\Users\\leona\\Documents\\Thesis_Project_UACH\\Temp\\Dataset\\BeesAnna\\sound_files\")\n",
        "\n",
        "# Output directory for the extracted .npy files and meta.json\n",
        "OUT_DIR = Path(r\"C:\\Users\\leona\\Documents\\Thesis_Project_UACH\\Temp\\Dataset\\BeesAnna\\features_bees\")\n",
        "\n",
        "\n",
        "# --- Audio & preprocessing ---\n",
        "SR        = 16000                   # target sample rate (Hz)\n",
        "TRIM_DB   = 30                      # trim leading/trailing silence below this dB\n",
        "USE_BANDPASS = True                 # light noise control via band-pass\n",
        "BP_LOW, BP_HIGH = 100, 1000         # Hz (tune after inspecting spectrograms)\n",
        "\n",
        "# --- Segmentation ---\n",
        "SEG_SEC   = 2.0                     # segment length (seconds)\n",
        "HOP_SEC   = 1.0                     # hop between segments (seconds)\n",
        "\n",
        "# --- Feature Type ---\n",
        "FEATURE_TYPE = \"logmel\"             # \"logmel\" (recommended) or \"mfcc\"\n",
        "\n",
        "# Log-Mel parameters\n",
        "N_MELS    = 64\n",
        "N_FFT     = int(0.025 * SR)         # 25 ms\n",
        "HOP_LEN   = int(0.010 * SR)         # 10 ms\n",
        "FMIN, FMAX = 20, SR // 2\n",
        "\n",
        "# MFCC parameters\n",
        "N_MFCC      = 32\n",
        "ADD_DELTAS  = True                  # stack Δ and ΔΔ for CNN channels\n",
        "\n",
        "# --- Splits & randomness ---\n",
        "RANDOM_SEED = 123\n",
        "TEST_SIZE   = 0.15\n",
        "VAL_SIZE    = 0.15                  # of remaining after taking out test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Utilities: file listing, labels, filters, loading, segmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "def list_wavs(root: Path):\n",
        "    files = []\n",
        "    classes = []\n",
        "    for class_dir in sorted(p for p in root.iterdir() if p.is_dir()):\n",
        "        label = class_dir.name\n",
        "        for wav in class_dir.rglob(\"*.wav\"):\n",
        "            files.append(wav)\n",
        "            classes.append(label)\n",
        "    return files, classes\n",
        "\n",
        "def label_to_index(labels):\n",
        "    labset = sorted(set(labels))\n",
        "    lab2idx = {lab:i for i,lab in enumerate(labset)}\n",
        "    y = np.array([lab2idx[l] for l in labels], dtype=np.int64)\n",
        "    return y, lab2idx\n",
        "\n",
        "def peak_normalize(x, eps=1e-9):\n",
        "    peak = np.max(np.abs(x)) + eps\n",
        "    return x / peak\n",
        "\n",
        "def bandpass_sos(sr, low_hz, high_hz, order=4):\n",
        "    sos = butter(order, [low_hz, high_hz], btype='bandpass', fs=sr, output='sos')\n",
        "    return sos\n",
        "\n",
        "def apply_bandpass(x, sr, low, high):\n",
        "    sos = bandpass_sos(sr, low, high)\n",
        "    return sosfiltfilt(sos, x)\n",
        "\n",
        "def load_and_clean(path):\n",
        "    # Load mono at target SR\n",
        "    x, _sr = librosa.load(path, sr=SR, mono=True)\n",
        "    # Trim leading/trailing silence\n",
        "    x, _ = librosa.effects.trim(x, top_db=TRIM_DB)\n",
        "    # Peak normalize\n",
        "    x = peak_normalize(x)\n",
        "    # Optional band-pass\n",
        "    if USE_BANDPASS:\n",
        "        x = apply_bandpass(x, SR, BP_LOW, BP_HIGH)\n",
        "    return x\n",
        "\n",
        "def segment_signal(x, sr, seg_sec, hop_sec):\n",
        "    seg_len = int(seg_sec * sr)\n",
        "    hop_len = int(hop_sec * sr)\n",
        "    if len(x) < seg_len:\n",
        "        # pad (reflect) so we have at least one segment\n",
        "        pad = seg_len - len(x)\n",
        "        x = np.pad(x, (0, pad), mode='reflect')\n",
        "    segments = []\n",
        "    for start in range(0, max(1, len(x)-seg_len+1), hop_len):\n",
        "        end = start + seg_len\n",
        "        seg = x[start:end]\n",
        "        if len(seg) < seg_len:\n",
        "            seg = np.pad(seg, (0, seg_len - len(seg)), mode='reflect')\n",
        "        segments.append(seg)\n",
        "    return segments"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Feature extraction: log-Mel (default) and MFCC (optional)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "def compute_logmel(seg):\n",
        "    S = librosa.feature.melspectrogram(\n",
        "        y=seg, sr=SR, n_fft=N_FFT, hop_length=HOP_LEN,\n",
        "        n_mels=N_MELS, fmin=FMIN, fmax=FMAX, power=2.0\n",
        "    )\n",
        "    logS = librosa.power_to_db(S, ref=np.max)\n",
        "    # (n_mels, T) -> (1, H, W) for CNNs\n",
        "    return logS[np.newaxis, :, :].astype(np.float32)\n",
        "\n",
        "def compute_mfcc(seg):\n",
        "    mfcc = librosa.feature.mfcc(\n",
        "        y=seg, sr=SR, n_mfcc=N_MFCC, n_fft=N_FFT, hop_length=HOP_LEN,\n",
        "        fmin=FMIN, fmax=FMAX\n",
        "    )\n",
        "    if ADD_DELTAS:\n",
        "        delta = librosa.feature.delta(mfcc)\n",
        "        delta2 = librosa.feature.delta(mfcc, order=2)\n",
        "        feat = np.stack([mfcc, delta, delta2], axis=0)  # (3, n_mfcc, T)\n",
        "    else:\n",
        "        feat = mfcc[np.newaxis, :, :]                    # (1, n_mfcc, T)\n",
        "    return feat.astype(np.float32)\n",
        "\n",
        "def featurize(seg):\n",
        "    if FEATURE_TYPE == \"logmel\":\n",
        "        return compute_logmel(seg)\n",
        "    elif FEATURE_TYPE == \"mfcc\":\n",
        "        return compute_mfcc(seg)\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown FEATURE_TYPE: {FEATURE_TYPE}\")\n",
        "\n",
        "def standardize_features(train_X, val_X, test_X, eps=1e-6):\n",
        "    # Per-channel standardization (mean/std over all samples and time-frequency bins)\n",
        "    C = train_X.shape[1]\n",
        "    means = []\n",
        "    stds = []\n",
        "    train_X_std = train_X.copy()\n",
        "    val_X_std = val_X.copy()\n",
        "    test_X_std = test_X.copy()\n",
        "    for c in range(C):\n",
        "        mu = train_X[:, c].mean()\n",
        "        sigma = train_X[:, c].std() + eps\n",
        "        means.append(float(mu))\n",
        "        stds.append(float(sigma))\n",
        "        train_X_std[:, c] = (train_X[:, c] - mu) / sigma\n",
        "        val_X_std[:, c]   = (val_X[:, c]   - mu) / sigma\n",
        "        test_X_std[:, c]  = (test_X[:, c]  - mu) / sigma\n",
        "    stats = {\"channel_means\": means, \"channel_stds\": stds}\n",
        "    return train_X_std, val_X_std, test_X_std, stats"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Build dataset and export `.npy` files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "ename": "SystemExit",
          "evalue": "No WAV files found under C:\\Users\\leona\\Documents\\Thesis_Project_UACH\\Temp\\Dataset\\BeesAnna\\sound_files. Expected class subfolders with .wav files.",
          "output_type": "error",
          "traceback": [
            "An exception has occurred, use %tb to see the full traceback.\n",
            "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m No WAV files found under C:\\Users\\leona\\Documents\\Thesis_Project_UACH\\Temp\\Dataset\\BeesAnna\\sound_files. Expected class subfolders with .wav files.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\leona\\.conda\\envs\\envBees\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3585: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
            "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
          ]
        }
      ],
      "source": [
        "random.seed(RANDOM_SEED)\n",
        "np.random.seed(RANDOM_SEED)\n",
        "\n",
        "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "wavs, labels = list_wavs(DATA_DIR)\n",
        "if not wavs:\n",
        "    raise SystemExit(f\"No WAV files found under {DATA_DIR}. Expected class subfolders with .wav files.\")\n",
        "\n",
        "y_all, lab2idx = label_to_index(labels)\n",
        "idx2lab = {v:k for k,v in lab2idx.items()}\n",
        "print(\"Classes:\", idx2lab)\n",
        "\n",
        "# Stratified split *by file* (not by segments)\n",
        "from sklearn.model_selection import train_test_split\n",
        "wavs = np.array(wavs)\n",
        "y_all = np.array(y_all)\n",
        "\n",
        "wavs_train, wavs_tmp, y_train, y_tmp = train_test_split(\n",
        "    wavs, y_all, test_size=TEST_SIZE, random_state=RANDOM_SEED, stratify=y_all\n",
        ")\n",
        "\n",
        "val_ratio_of_remaining = VAL_SIZE / (1.0 - TEST_SIZE)\n",
        "wavs_val, wavs_test, y_val, y_test = train_test_split(\n",
        "    wavs_tmp, y_tmp, test_size=1.0 - val_ratio_of_remaining,\n",
        "    random_state=RANDOM_SEED, stratify=y_tmp\n",
        ")\n",
        "\n",
        "def process_many(file_list, labels_list):\n",
        "    feats = []\n",
        "    labs  = []\n",
        "    for path, lab in zip(file_list, labels_list):\n",
        "        x = load_and_clean(str(path))\n",
        "        segments = segment_signal(x, SR, SEG_SEC, HOP_SEC)\n",
        "        for seg in segments:\n",
        "            f = featurize(seg)  # (C,H,W)\n",
        "            feats.append(f)\n",
        "            labs.append(lab)\n",
        "    X = np.stack(feats, axis=0)   # (N,C,H,W)\n",
        "    y = np.array(labs, dtype=np.int64)\n",
        "    return X, y\n",
        "\n",
        "print(\"Processing TRAIN...\")\n",
        "X_train, y_train = process_many(wavs_train, y_train)\n",
        "print(\"Processing VAL...\")\n",
        "X_val, y_val     = process_many(wavs_val, y_val)\n",
        "print(\"Processing TEST...\")\n",
        "X_test, y_test   = process_many(wavs_test, y_test)\n",
        "\n",
        "print(\"Standardizing features (train stats only)...\")\n",
        "X_train, X_val, X_test, stats = standardize_features(X_train, X_val, X_test)\n",
        "\n",
        "# Save arrays and metadata\n",
        "np.save(OUT_DIR / \"X_train.npy\", X_train)\n",
        "np.save(OUT_DIR / \"y_train.npy\", y_train)\n",
        "np.save(OUT_DIR / \"X_val.npy\",   X_val)\n",
        "np.save(OUT_DIR / \"y_val.npy\",   y_val)\n",
        "np.save(OUT_DIR / \"X_test.npy\",  X_test)\n",
        "np.save(OUT_DIR / \"y_test.npy\",  y_test)\n",
        "\n",
        "with open(OUT_DIR / \"meta.json\", \"w\") as f:\n",
        "    json.dump({\n",
        "        \"sr\": SR,\n",
        "        \"segment_seconds\": SEG_SEC,\n",
        "        \"hop_seconds\": HOP_SEC,\n",
        "        \"feature_type\": FEATURE_TYPE,\n",
        "        \"n_mels\": int(N_MELS) if FEATURE_TYPE==\"logmel\" else None,\n",
        "        \"n_mfcc\": int(N_MFCC) if FEATURE_TYPE==\"mfcc\" else None,\n",
        "        \"add_deltas\": bool(ADD_DELTAS) if FEATURE_TYPE==\"mfcc\" else None,\n",
        "        \"classes\": {int(k): v for k, v in idx2lab.items()},\n",
        "        \"standardization\": stats,\n",
        "        \"bandpass\": {\"enabled\": bool(USE_BANDPASS), \"low\": int(BP_LOW), \"high\": int(BP_HIGH)}\n",
        "    }, f, indent=2)\n",
        "\n",
        "print(\"Saved features to:\", OUT_DIR.resolve())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Sanity check"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Reload and inspect shapes to verify downstream compatibility\n",
        "Xt = np.load(OUT_DIR / \"X_train.npy\")\n",
        "yt = np.load(OUT_DIR / \"y_train.npy\")\n",
        "print(\"X_train shape:\", Xt.shape, \"(N, C, H, W)\")\n",
        "print(\"y_train shape:\", yt.shape)\n",
        "print(\"Feature type:\", FEATURE_TYPE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## (Optional) Visual preview of one feature map"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# %matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "Xt = np.load(OUT_DIR / \"X_train.npy\")\n",
        "yt = np.load(OUT_DIR / \"y_train.npy\")\n",
        "\n",
        "i = 0  # change index to preview other samples\n",
        "feat = Xt[i]  # (C,H,W)\n",
        "\n",
        "# show first channel\n",
        "plt.figure()\n",
        "plt.imshow(feat[0], aspect=\"auto\", origin=\"lower\")\n",
        "plt.title(f\"Channel 0 - {FEATURE_TYPE}\")\n",
        "plt.xlabel(\"Frames\"); plt.ylabel(\"Bins\")\n",
        "plt.colorbar()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
