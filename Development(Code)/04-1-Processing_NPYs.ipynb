{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0e62ef8",
   "metadata": {},
   "source": [
    "# Step-by-Step: From MFCC ```.npy``` Files to a Model\n",
    "\n",
    "## Step 1: Load Metadata\n",
    "\n",
    "We’ll read ```mfcc_metadata.csv``` to get:\n",
    "- The name of the ```.npy``` file with MFCCs,\n",
    "- The ```queen_status``` label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b80840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "queen_status\n",
      "3    3563\n",
      "2    1553\n",
      "0    1038\n",
      "1     946\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "# Load metadata file\n",
    "metadata_df = pd.read_csv(\"mfcc_metadata.csv\")\n",
    "\n",
    "# Optional: Show distribution of labels\n",
    "print(metadata_df[\"queen_status\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "390f2da8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ruta: C:\\Users\\leona\\Documents\\Thesis_Project_UACH\\Development(Code)\\mfcc_files_03-1\\metadata.csv\n",
      "Existe: True\n",
      "Tamaño bytes: 2\n",
      "Preview:\n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "META_PATH = Path(\"mfcc_files_03-1\") / \"metadata.csv\"\n",
    "print(\"Ruta:\", META_PATH.resolve())\n",
    "print(\"Existe:\", META_PATH.exists())\n",
    "print(\"Tamaño bytes:\", META_PATH.stat().st_size if META_PATH.exists() else -1)\n",
    "\n",
    "# Muestra las primeras líneas (si tuviera)\n",
    "import itertools\n",
    "if META_PATH.exists() and META_PATH.stat().st_size > 0:\n",
    "    with open(META_PATH, \"r\", encoding=\"utf-8\", errors=\"replace\") as f:\n",
    "        print(\"Preview:\\n\", \"\".join(list(itertools.islice(f, 5))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd5d36d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NPYs encontrados: 7100\n"
     ]
    }
   ],
   "source": [
    "mfcc_dir = Path(\"mfcc_files_03-1\") / \"mfcc_cmvn_noc0\"   # o la subcarpeta real que uses\n",
    "files = sorted(mfcc_dir.glob(\"*.npy\"))\n",
    "print(\"NPYs encontrados:\", len(files))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea330047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metadata.csv reconstruido con 7100 filas\n"
     ]
    }
   ],
   "source": [
    "mfcc_dir = Path(\"mfcc_files_03-1\") / \"mfcc_cmvn_noc0\"   # ajusta si usas otra carpeta\n",
    "files = sorted(mfcc_dir.glob(\"*.npy\"))\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    \"mfcc_file\": [f.name for f in files],\n",
    "    \"mfcc_path\": [str(f) for f in files],\n",
    "    # TODO: añade tus etiquetas reales aquí haciendo merge con tu fuente de labels\n",
    "    # \"queen_status\": ...\n",
    "})\n",
    "df.to_csv(Path(\"mfcc_files_03-1\") / \"metadata.csv\", index=False, encoding=\"utf-8\")\n",
    "print(\"metadata.csv reconstruido con\", len(df), \"filas\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f550de47",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_df = pd.read_csv(\"mfcc_files_03-1/metadata.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "970c62c7",
   "metadata": {},
   "source": [
    "## Step 2: Prepare Data (Fixed Length for Simpler Models)\n",
    "\n",
    "We’ll:\n",
    "- Load the MFCC matrix from each .npy file,\n",
    "- Pad or truncate it to a fixed number of frames (say, 100),\n",
    "- Flatten it into a 1D vector (so you can use traditional models like Random Forest or Logistic Regression)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "89ce5803",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\leona\\\\Documents\\\\Thesis_Project_UACH\\\\Development(Code)'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cd3d7ce2",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Tu metadata no trae columna de etiqueta ('queen_status' / 'label'). Necesitas añadir etiquetas o hacer un merge con tu archivo de labels.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 28\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# Aplica las transformaciones\u001b[39;00m\n\u001b[0;32m     27\u001b[0m metadata_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmfcc_path\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m metadata_df\u001b[38;5;241m.\u001b[39mapply(derive_mfcc_path, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 28\u001b[0m LABEL_COL \u001b[38;5;241m=\u001b[39m \u001b[43mpick_label_column\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmetadata_df\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# Sanity check: archivos existentes\u001b[39;00m\n\u001b[0;32m     31\u001b[0m missing \u001b[38;5;241m=\u001b[39m [p \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m metadata_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmfcc_path\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m Path(p)\u001b[38;5;241m.\u001b[39mexists()]\n",
      "Cell \u001b[1;32mIn[23], line 8\u001b[0m, in \u001b[0;36mpick_label_column\u001b[1;34m(df)\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m df\u001b[38;5;241m.\u001b[39mcolumns:\n\u001b[0;32m      7\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m c\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTu metadata no trae columna de etiqueta (\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mqueen_status\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m / \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m). \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNecesitas añadir etiquetas o hacer un merge con tu archivo de labels.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     11\u001b[0m )\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Tu metadata no trae columna de etiqueta ('queen_status' / 'label'). Necesitas añadir etiquetas o hacer un merge con tu archivo de labels."
     ]
    }
   ],
   "source": [
    "# subcarpeta donde 03-1 guardó los MFCC\n",
    "MFCC_SUBDIR = \"mfcc_cmvn_noc0\"   # usa \"mfcc_raw\" si cambiaste flags\n",
    "\n",
    "def pick_label_column(df):\n",
    "    for c in [\"queen_status\", \"label\", \"has_queen\", \"status\"]:\n",
    "        if c in df.columns:\n",
    "            return c\n",
    "    raise RuntimeError(\n",
    "        \"Tu metadata no trae columna de etiqueta ('queen_status' / 'label'). \"\n",
    "        \"Necesitas añadir etiquetas o hacer un merge con tu archivo de labels.\"\n",
    "    )\n",
    "\n",
    "def derive_mfcc_path(row):\n",
    "    # Usa ruta directa si ya existe una columna tipo 'mfcc_path'\n",
    "    for c in [\"mfcc_path\", \"mfcc_file\", \"mfcc\"]:\n",
    "        if c in row and isinstance(row[c], str) and row[c]:\n",
    "            p = Path(row[c])\n",
    "            if p.is_absolute() or str(p).startswith(\"mfcc_files_03-1\"):\n",
    "                return str(p)\n",
    "            return str(Path(\"mfcc_files_03-1\") / MFCC_SUBDIR / p.name)\n",
    "    # Si no hay columna, construye a partir de 'id'\n",
    "    if \"id\" in row:\n",
    "        return str(Path(\"mfcc_files_03-1\") / MFCC_SUBDIR / f\"{row['id']}_mfcc.npy\")\n",
    "    raise RuntimeError(\"No hay forma de deducir el nombre del .npy (falta 'mfcc_file' o 'id').\")\n",
    "\n",
    "# Aplica las transformaciones\n",
    "metadata_df[\"mfcc_path\"] = metadata_df.apply(derive_mfcc_path, axis=1)\n",
    "LABEL_COL = pick_label_column(metadata_df)\n",
    "\n",
    "# Sanity check: archivos existentes\n",
    "missing = [p for p in metadata_df[\"mfcc_path\"] if not Path(p).exists()]\n",
    "if missing:\n",
    "    print(\"Archivos MFCC que no existen (muestra 5):\", missing[:5])\n",
    "    raise FileNotFoundError(\"Hay rutas de MFCC inexistentes. Revisa MFCC_SUBDIR y nombres.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bc3770b6",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'queen_status'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\leona\\.conda\\envs\\envBees\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'queen_status'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 16\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, row \u001b[38;5;129;01min\u001b[39;00m metadata_df\u001b[38;5;241m.\u001b[39miterrows():\n\u001b[0;32m     15\u001b[0m     file_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(mfcc_dir, row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmfcc_file\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m---> 16\u001b[0m     label \u001b[38;5;241m=\u001b[39m \u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mqueen_status\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;66;03m# Load MFCC matrix\u001b[39;00m\n\u001b[0;32m     19\u001b[0m     mfcc \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mload(file_path)\n",
      "File \u001b[1;32mc:\\Users\\leona\\.conda\\envs\\envBees\\lib\\site-packages\\pandas\\core\\series.py:1121\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1118\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[key]\n\u001b[0;32m   1120\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m key_is_scalar:\n\u001b[1;32m-> 1121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1123\u001b[0m \u001b[38;5;66;03m# Convert generator to list before going through hashable part\u001b[39;00m\n\u001b[0;32m   1124\u001b[0m \u001b[38;5;66;03m# (We will iterate through the generator there to check for slices)\u001b[39;00m\n\u001b[0;32m   1125\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n",
      "File \u001b[1;32mc:\\Users\\leona\\.conda\\envs\\envBees\\lib\\site-packages\\pandas\\core\\series.py:1237\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[1;34m(self, label, takeable)\u001b[0m\n\u001b[0;32m   1234\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[label]\n\u001b[0;32m   1236\u001b[0m \u001b[38;5;66;03m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[1;32m-> 1237\u001b[0m loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1239\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(loc):\n\u001b[0;32m   1240\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[loc]\n",
      "File \u001b[1;32mc:\\Users\\leona\\.conda\\envs\\envBees\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'queen_status'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Settings\n",
    "mfcc_dir = \"mfcc_files_03-1/\"\n",
    "n_mfcc = 12\n",
    "max_frames = 100  # You can adjust this if needed\n",
    "\n",
    "# Containers for features and labels\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "# Loop through metadata and load MFCCs\n",
    "for idx, row in metadata_df.iterrows():\n",
    "    file_path = os.path.join(mfcc_dir, row[\"mfcc_file\"])\n",
    "    label = row[\"queen_status\"]\n",
    "\n",
    "    # Load MFCC matrix\n",
    "    mfcc = np.load(file_path)\n",
    "\n",
    "    # Pad or truncate to fixed length\n",
    "    if mfcc.shape[0] < max_frames:\n",
    "        pad_width = max_frames - mfcc.shape[0]\n",
    "        mfcc = np.pad(mfcc, ((0, pad_width), (0, 0)), mode=\"constant\")\n",
    "    else:\n",
    "        mfcc = mfcc[:max_frames]\n",
    "\n",
    "    # Flatten to 1D vector: [100 frames × 13 mfccs] → 1300 features\n",
    "    X.append(mfcc.flatten())\n",
    "    y.append(label)\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "print(\"Loaded and prepared all data:\", X.shape, y.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc58c282",
   "metadata": {},
   "source": [
    "## Step 3: Train a Simple Model (Random Forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a5cdf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.35      0.49       208\n",
      "           1       0.63      0.18      0.28       189\n",
      "           2       0.64      0.46      0.53       310\n",
      "           3       0.65      0.97      0.78       713\n",
      "\n",
      "    accuracy                           0.66      1420\n",
      "   macro avg       0.69      0.49      0.52      1420\n",
      "weighted avg       0.67      0.66      0.62      1420\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "# Train model\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate\n",
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f9ede52",
   "metadata": {},
   "source": [
    "## What We’ll Get:\n",
    "- A first working classifier that predicts queen status from MFCC audio features.\n",
    "- Precision, recall, F1-score — all the standard metrics.\n",
    "- A real baseline you can compare future models to (like RNNs or CNNs).\n",
    "\n",
    "## Next Levels\n",
    "- Normalize MFCCs before modeling.\n",
    "- Try PCA for feature reduction.\n",
    "- Train time-distributed models (like LSTMs) using the full [frames × 13] matrices.\n",
    "- Visualize samples: MFCC heatmaps vs. queen status."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "envBees",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
