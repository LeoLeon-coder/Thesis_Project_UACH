{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70ce968f",
   "metadata": {},
   "source": [
    "# Cell 1 — Config (paths + MFCC params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef8f9c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "# --- Paths ---\n",
    "DATA_DIR = Path(r\"C:\\Users\\leona\\Documents\\Thesis_Project_UACH\\Temp\\Dataset\\BeesAnna\\sound_files\")\n",
    "CSV_PATH = Path(r\"C:\\Users\\leona\\Documents\\Thesis_Project_UACH\\Temp\\Dataset\\BeesAnna\\all_data_updated.csv\")\n",
    "\n",
    "UNLABELED_DIR = Path(r\"C:\\Users\\leona\\Documents\\Thesis_Project_UACH\\Temp\\Dataset\\features_mfcc_unlabeled\")\n",
    "UNLABELED_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "OUT_X = UNLABELED_DIR / \"X_unlabeled.npy\"\n",
    "OUT_INDEX = UNLABELED_DIR / \"unlabeled_index.json\"\n",
    "OUT_META = UNLABELED_DIR / \"meta_unlabeled.json\"\n",
    "\n",
    "# --- CSV columns ---\n",
    "ID_COL = \"file name\"\n",
    "TARGET_COL = \"queen status\"\n",
    "VALID_CLASSES = {0, 1, 2, 3}\n",
    "\n",
    "# --- Audio / MFCC parameters (match your labeled pipeline) ---\n",
    "SR = 16000\n",
    "TRIM_DB = 30\n",
    "\n",
    "SEG_SEC = 2.0\n",
    "HOP_SEC = 1.0\n",
    "\n",
    "N_MFCC = 32\n",
    "N_FFT  = int(0.025 * SR)   # 25 ms\n",
    "HOP_LEN= int(0.010 * SR)   # 10 ms\n",
    "FMIN, FMAX = 20, SR // 2\n",
    "\n",
    "ADD_DELTAS = True\n",
    "\n",
    "# --- Output dtype ---\n",
    "# float16 saves ~50% disk; safe for features; you can cast back to float32 during training.\n",
    "OUT_DTYPE = np.float16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a355d4b6",
   "metadata": {},
   "source": [
    "# Cell 2 — Define helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d4e4cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def peak_normalize(x, eps=1e-9):\n",
    "    return x / (np.max(np.abs(x)) + eps)\n",
    "\n",
    "def load_and_clean(path):\n",
    "    x, _ = librosa.load(str(path), sr=SR, mono=True)\n",
    "    x, _ = librosa.effects.trim(x, top_db=TRIM_DB)\n",
    "    x = peak_normalize(x)\n",
    "    return x\n",
    "\n",
    "def segment_signal(x, sr, seg_sec, hop_sec):\n",
    "    seg_len = int(seg_sec * sr)\n",
    "    hop_len = int(hop_sec * sr)\n",
    "\n",
    "    if len(x) < seg_len:\n",
    "        x = np.pad(x, (0, seg_len - len(x)), mode=\"reflect\")\n",
    "\n",
    "    segments = []\n",
    "    for start in range(0, max(1, len(x)-seg_len+1), hop_len):\n",
    "        seg = x[start:start+seg_len]\n",
    "        if len(seg) < seg_len:\n",
    "            seg = np.pad(seg, (0, seg_len - len(seg)), mode=\"reflect\")\n",
    "        segments.append(seg)\n",
    "    return segments\n",
    "\n",
    "def mfcc_features(seg):\n",
    "    mfcc = librosa.feature.mfcc(\n",
    "        y=seg, sr=SR, n_mfcc=N_MFCC, n_fft=N_FFT, hop_length=HOP_LEN,\n",
    "        fmin=FMIN, fmax=FMAX\n",
    "    )\n",
    "    if ADD_DELTAS:\n",
    "        d1 = librosa.feature.delta(mfcc)\n",
    "        d2 = librosa.feature.delta(mfcc, order=2)\n",
    "        feat = np.stack([mfcc, d1, d2], axis=0)   # (3, n_mfcc, T)\n",
    "    else:\n",
    "        feat = mfcc[np.newaxis, :, :]             # (1, n_mfcc, T)\n",
    "    return feat.astype(np.float32)  # compute in float32; cast to OUT_DTYPE when writing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae64103",
   "metadata": {},
   "source": [
    "# Cell 3 — Build the unlabeled file list (exclude the 1275 labeled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "733aec95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total WAVs in folder: 14200\n",
      "Labeled WAVs in CSV (valid 0-3): 1275\n",
      "Unlabeled WAVs (to process): 11650\n"
     ]
    }
   ],
   "source": [
    "# All WAVs\n",
    "wav_paths = sorted(list(DATA_DIR.rglob(\"*.wav\"))) + sorted(list(DATA_DIR.rglob(\"*.WAV\")))\n",
    "wav_by_name = {p.name: p for p in wav_paths}\n",
    "\n",
    "print(\"Total WAVs in folder:\", len(wav_paths))\n",
    "\n",
    "# Read CSV and extract labeled basenames\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "assert ID_COL in df.columns, f\"Missing column: {ID_COL}\"\n",
    "assert TARGET_COL in df.columns, f\"Missing column: {TARGET_COL}\"\n",
    "\n",
    "df[\"_basename\"] = df[ID_COL].astype(str).map(lambda s: Path(s).name)\n",
    "df[\"_y\"] = pd.to_numeric(df[TARGET_COL], errors=\"coerce\")\n",
    "\n",
    "labeled_names = set(df.loc[df[\"_y\"].isin(list(VALID_CLASSES)), \"_basename\"])\n",
    "print(\"Labeled WAVs in CSV (valid 0-3):\", len(labeled_names))\n",
    "\n",
    "# Unlabeled = WAVs not in labeled set\n",
    "unlabeled_paths = [p for p in wav_paths if p.name not in labeled_names]\n",
    "print(\"Unlabeled WAVs (to process):\", len(unlabeled_paths))\n",
    "\n",
    "# Sanity\n",
    "if len(unlabeled_paths) == 0:\n",
    "    raise SystemExit(\"No unlabeled WAVs found. Check CSV/paths.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89c8187e",
   "metadata": {},
   "source": [
    "# Cell 4 — PASS 1: count segments and keep only “good” files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ddfa62b",
   "metadata": {},
   "source": [
    "We do a first pass so we can preallocate the ```.npy``` memmap with the correct shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4bae67a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\leona\\.conda\\envs\\envBees\\lib\\site-packages\\librosa\\core\\intervals.py:8: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import resource_filename\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pass1: 200/11650 | good=200 | failed=0\n",
      "Pass1: 400/11650 | good=400 | failed=0\n",
      "Pass1: 600/11650 | good=600 | failed=0\n",
      "Pass1: 800/11650 | good=800 | failed=0\n",
      "Pass1: 1000/11650 | good=1000 | failed=0\n",
      "Pass1: 1200/11650 | good=1200 | failed=0\n",
      "Pass1: 1400/11650 | good=1400 | failed=0\n",
      "Pass1: 1600/11650 | good=1600 | failed=0\n",
      "Pass1: 1800/11650 | good=1800 | failed=0\n",
      "Pass1: 2000/11650 | good=2000 | failed=0\n",
      "Pass1: 2200/11650 | good=2200 | failed=0\n",
      "Pass1: 2400/11650 | good=2400 | failed=0\n",
      "Pass1: 2600/11650 | good=2600 | failed=0\n",
      "Pass1: 2800/11650 | good=2800 | failed=0\n",
      "Pass1: 3000/11650 | good=3000 | failed=0\n",
      "Pass1: 3200/11650 | good=3200 | failed=0\n",
      "Pass1: 3400/11650 | good=3400 | failed=0\n",
      "Pass1: 3600/11650 | good=3600 | failed=0\n",
      "Pass1: 3800/11650 | good=3800 | failed=0\n",
      "Pass1: 4000/11650 | good=4000 | failed=0\n",
      "Pass1: 4200/11650 | good=4200 | failed=0\n",
      "Pass1: 4400/11650 | good=4400 | failed=0\n",
      "Pass1: 4600/11650 | good=4600 | failed=0\n",
      "Pass1: 4800/11650 | good=4800 | failed=0\n",
      "Pass1: 5000/11650 | good=5000 | failed=0\n",
      "Pass1: 5200/11650 | good=5200 | failed=0\n",
      "Pass1: 5400/11650 | good=5400 | failed=0\n",
      "Pass1: 5600/11650 | good=5600 | failed=0\n",
      "Pass1: 5800/11650 | good=5800 | failed=0\n",
      "Pass1: 6000/11650 | good=6000 | failed=0\n",
      "Pass1: 6200/11650 | good=6200 | failed=0\n",
      "Pass1: 6400/11650 | good=6400 | failed=0\n",
      "Pass1: 6600/11650 | good=6600 | failed=0\n",
      "Pass1: 6800/11650 | good=6800 | failed=0\n",
      "Pass1: 7000/11650 | good=7000 | failed=0\n",
      "Pass1: 7200/11650 | good=7200 | failed=0\n",
      "Pass1: 7400/11650 | good=7400 | failed=0\n",
      "Pass1: 7600/11650 | good=7600 | failed=0\n",
      "Pass1: 7800/11650 | good=7800 | failed=0\n",
      "Pass1: 8000/11650 | good=8000 | failed=0\n",
      "Pass1: 8200/11650 | good=8200 | failed=0\n",
      "Pass1: 8400/11650 | good=8400 | failed=0\n",
      "Pass1: 8600/11650 | good=8600 | failed=0\n",
      "Pass1: 8800/11650 | good=8800 | failed=0\n",
      "Pass1: 9000/11650 | good=9000 | failed=0\n",
      "Pass1: 9200/11650 | good=9200 | failed=0\n",
      "Pass1: 9400/11650 | good=9400 | failed=0\n",
      "Pass1: 9600/11650 | good=9600 | failed=0\n",
      "Pass1: 9800/11650 | good=9800 | failed=0\n",
      "Pass1: 10000/11650 | good=10000 | failed=0\n",
      "Pass1: 10200/11650 | good=10200 | failed=0\n",
      "Pass1: 10400/11650 | good=10400 | failed=0\n",
      "Pass1: 10600/11650 | good=10600 | failed=0\n",
      "Pass1: 10800/11650 | good=10800 | failed=0\n",
      "Pass1: 11000/11650 | good=11000 | failed=0\n",
      "Pass1: 11200/11650 | good=11200 | failed=0\n",
      "Pass1: 11400/11650 | good=11400 | failed=0\n",
      "Pass1: 11600/11650 | good=11600 | failed=0\n",
      "Pass1: 11650/11650 | good=11650 | failed=0\n",
      "\n",
      "Good files: 11650\n",
      "Failed files: 0\n",
      "Total segments to write: 687350\n"
     ]
    }
   ],
   "source": [
    "good_files = []\n",
    "seg_counts = []\n",
    "failed = []\n",
    "\n",
    "total = len(unlabeled_paths)\n",
    "\n",
    "for i, p in enumerate(unlabeled_paths, 1):\n",
    "    try:\n",
    "        x = load_and_clean(p)\n",
    "        segs = segment_signal(x, SR, SEG_SEC, HOP_SEC)\n",
    "        good_files.append(p)\n",
    "        seg_counts.append(len(segs))\n",
    "    except Exception as e:\n",
    "        failed.append({\"file\": str(p), \"error\": str(e)})\n",
    "\n",
    "    if i % 200 == 0 or i == total:\n",
    "        print(f\"Pass1: {i}/{total} | good={len(good_files)} | failed={len(failed)}\")\n",
    "\n",
    "total_segments = int(np.sum(seg_counts))\n",
    "print(\"\\nGood files:\", len(good_files))\n",
    "print(\"Failed files:\", len(failed))\n",
    "print(\"Total segments to write:\", total_segments)\n",
    "\n",
    "if total_segments == 0:\n",
    "    raise SystemExit(\"Total segments is 0. Something is wrong with segmentation/loading.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d7b155a",
   "metadata": {},
   "source": [
    "# Cell 5 — Preallocate ```X_unlabeled.npy``` as a memmapped ```.npy``` file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52796963",
   "metadata": {},
   "source": [
    "We also compute the fixed feature shape ```(C, n_mfcc, T)``` once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cfab0a22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature per segment shape: (3, 32, 201)\n",
      "Allocated: C:\\Users\\leona\\Documents\\Thesis_Project_UACH\\Temp\\Dataset\\features_mfcc_unlabeled\\X_unlabeled.npy\n",
      "Memmap shape: (687350, 3, 32, 201) dtype: float16\n"
     ]
    }
   ],
   "source": [
    "# Determine feature shape using a dummy segment\n",
    "seg_len = int(SEG_SEC * SR)\n",
    "dummy = np.zeros(seg_len, dtype=np.float32)\n",
    "dummy_feat = mfcc_features(dummy)\n",
    "C, H, W = dummy_feat.shape\n",
    "\n",
    "print(\"Feature per segment shape:\", (C, H, W))\n",
    "\n",
    "# Create memmap .npy with known shape\n",
    "X_mm = np.lib.format.open_memmap(\n",
    "    OUT_X, mode=\"w+\",\n",
    "    dtype=OUT_DTYPE,\n",
    "    shape=(total_segments, C, H, W)\n",
    ")\n",
    "\n",
    "print(\"Allocated:\", OUT_X)\n",
    "print(\"Memmap shape:\", X_mm.shape, \"dtype:\", X_mm.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67369e11",
   "metadata": {},
   "source": [
    "# Cell 6 — PASS 2: extract MFCC and write directly into the memmap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30cb5a13",
   "metadata": {},
   "source": [
    "Also writes a compact index: per file start offset and number of segments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "700cc276",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pass2: 100/11650 | written segments=5900/687350\n",
      "Pass2: 200/11650 | written segments=11800/687350\n",
      "Pass2: 300/11650 | written segments=17700/687350\n",
      "Pass2: 400/11650 | written segments=23600/687350\n",
      "Pass2: 500/11650 | written segments=29500/687350\n",
      "Pass2: 600/11650 | written segments=35400/687350\n",
      "Pass2: 700/11650 | written segments=41300/687350\n",
      "Pass2: 800/11650 | written segments=47200/687350\n",
      "Pass2: 900/11650 | written segments=53100/687350\n",
      "Pass2: 1000/11650 | written segments=59000/687350\n",
      "Pass2: 1100/11650 | written segments=64900/687350\n",
      "Pass2: 1200/11650 | written segments=70800/687350\n",
      "Pass2: 1300/11650 | written segments=76700/687350\n",
      "Pass2: 1400/11650 | written segments=82600/687350\n",
      "Pass2: 1500/11650 | written segments=88500/687350\n",
      "Pass2: 1600/11650 | written segments=94400/687350\n",
      "Pass2: 1700/11650 | written segments=100300/687350\n",
      "Pass2: 1800/11650 | written segments=106200/687350\n",
      "Pass2: 1900/11650 | written segments=112100/687350\n",
      "Pass2: 2000/11650 | written segments=118000/687350\n",
      "Pass2: 2100/11650 | written segments=123900/687350\n",
      "Pass2: 2200/11650 | written segments=129800/687350\n",
      "Pass2: 2300/11650 | written segments=135700/687350\n",
      "Pass2: 2400/11650 | written segments=141600/687350\n",
      "Pass2: 2500/11650 | written segments=147500/687350\n",
      "Pass2: 2600/11650 | written segments=153400/687350\n",
      "Pass2: 2700/11650 | written segments=159300/687350\n",
      "Pass2: 2800/11650 | written segments=165200/687350\n",
      "Pass2: 2900/11650 | written segments=171100/687350\n",
      "Pass2: 3000/11650 | written segments=177000/687350\n",
      "Pass2: 3100/11650 | written segments=182900/687350\n",
      "Pass2: 3200/11650 | written segments=188800/687350\n",
      "Pass2: 3300/11650 | written segments=194700/687350\n",
      "Pass2: 3400/11650 | written segments=200600/687350\n",
      "Pass2: 3500/11650 | written segments=206500/687350\n",
      "Pass2: 3600/11650 | written segments=212400/687350\n",
      "Pass2: 3700/11650 | written segments=218300/687350\n",
      "Pass2: 3800/11650 | written segments=224200/687350\n",
      "Pass2: 3900/11650 | written segments=230100/687350\n",
      "Pass2: 4000/11650 | written segments=236000/687350\n",
      "Pass2: 4100/11650 | written segments=241900/687350\n",
      "Pass2: 4200/11650 | written segments=247800/687350\n",
      "Pass2: 4300/11650 | written segments=253700/687350\n",
      "Pass2: 4400/11650 | written segments=259600/687350\n",
      "Pass2: 4500/11650 | written segments=265500/687350\n",
      "Pass2: 4600/11650 | written segments=271400/687350\n",
      "Pass2: 4700/11650 | written segments=277300/687350\n",
      "Pass2: 4800/11650 | written segments=283200/687350\n",
      "Pass2: 4900/11650 | written segments=289100/687350\n",
      "Pass2: 5000/11650 | written segments=295000/687350\n",
      "Pass2: 5100/11650 | written segments=300900/687350\n",
      "Pass2: 5200/11650 | written segments=306800/687350\n",
      "Pass2: 5300/11650 | written segments=312700/687350\n",
      "Pass2: 5400/11650 | written segments=318600/687350\n",
      "Pass2: 5500/11650 | written segments=324500/687350\n",
      "Pass2: 5600/11650 | written segments=330400/687350\n",
      "Pass2: 5700/11650 | written segments=336300/687350\n",
      "Pass2: 5800/11650 | written segments=342200/687350\n",
      "Pass2: 5900/11650 | written segments=348100/687350\n",
      "Pass2: 6000/11650 | written segments=354000/687350\n",
      "Pass2: 6100/11650 | written segments=359900/687350\n",
      "Pass2: 6200/11650 | written segments=365800/687350\n",
      "Pass2: 6300/11650 | written segments=371700/687350\n",
      "Pass2: 6400/11650 | written segments=377600/687350\n",
      "Pass2: 6500/11650 | written segments=383500/687350\n",
      "Pass2: 6600/11650 | written segments=389400/687350\n",
      "Pass2: 6700/11650 | written segments=395300/687350\n",
      "Pass2: 6800/11650 | written segments=401200/687350\n",
      "Pass2: 6900/11650 | written segments=407100/687350\n",
      "Pass2: 7000/11650 | written segments=413000/687350\n",
      "Pass2: 7100/11650 | written segments=418900/687350\n",
      "Pass2: 7200/11650 | written segments=424800/687350\n",
      "Pass2: 7300/11650 | written segments=430700/687350\n",
      "Pass2: 7400/11650 | written segments=436600/687350\n",
      "Pass2: 7500/11650 | written segments=442500/687350\n",
      "Pass2: 7600/11650 | written segments=448400/687350\n",
      "Pass2: 7700/11650 | written segments=454300/687350\n",
      "Pass2: 7800/11650 | written segments=460200/687350\n",
      "Pass2: 7900/11650 | written segments=466100/687350\n",
      "Pass2: 8000/11650 | written segments=472000/687350\n",
      "Pass2: 8100/11650 | written segments=477900/687350\n",
      "Pass2: 8200/11650 | written segments=483800/687350\n",
      "Pass2: 8300/11650 | written segments=489700/687350\n",
      "Pass2: 8400/11650 | written segments=495600/687350\n",
      "Pass2: 8500/11650 | written segments=501500/687350\n",
      "Pass2: 8600/11650 | written segments=507400/687350\n",
      "Pass2: 8700/11650 | written segments=513300/687350\n",
      "Pass2: 8800/11650 | written segments=519200/687350\n",
      "Pass2: 8900/11650 | written segments=525100/687350\n",
      "Pass2: 9000/11650 | written segments=531000/687350\n",
      "Pass2: 9100/11650 | written segments=536900/687350\n",
      "Pass2: 9200/11650 | written segments=542800/687350\n",
      "Pass2: 9300/11650 | written segments=548700/687350\n",
      "Pass2: 9400/11650 | written segments=554600/687350\n",
      "Pass2: 9500/11650 | written segments=560500/687350\n",
      "Pass2: 9600/11650 | written segments=566400/687350\n",
      "Pass2: 9700/11650 | written segments=572300/687350\n",
      "Pass2: 9800/11650 | written segments=578200/687350\n",
      "Pass2: 9900/11650 | written segments=584100/687350\n",
      "Pass2: 10000/11650 | written segments=590000/687350\n",
      "Pass2: 10100/11650 | written segments=595900/687350\n",
      "Pass2: 10200/11650 | written segments=601800/687350\n",
      "Pass2: 10300/11650 | written segments=607700/687350\n",
      "Pass2: 10400/11650 | written segments=613600/687350\n",
      "Pass2: 10500/11650 | written segments=619500/687350\n",
      "Pass2: 10600/11650 | written segments=625400/687350\n",
      "Pass2: 10700/11650 | written segments=631300/687350\n",
      "Pass2: 10800/11650 | written segments=637200/687350\n",
      "Pass2: 10900/11650 | written segments=643100/687350\n",
      "Pass2: 11000/11650 | written segments=649000/687350\n",
      "Pass2: 11100/11650 | written segments=654900/687350\n",
      "Pass2: 11200/11650 | written segments=660800/687350\n",
      "Pass2: 11300/11650 | written segments=666700/687350\n",
      "Pass2: 11400/11650 | written segments=672600/687350\n",
      "Pass2: 11500/11650 | written segments=678500/687350\n",
      "Pass2: 11600/11650 | written segments=684400/687350\n",
      "Pass2: 11650/11650 | written segments=687350/687350\n",
      "\n",
      "Done writing: C:\\Users\\leona\\Documents\\Thesis_Project_UACH\\Temp\\Dataset\\features_mfcc_unlabeled\\X_unlabeled.npy\n",
      "Total written: 687350 Expected: 687350\n"
     ]
    }
   ],
   "source": [
    "write_pos = 0\n",
    "index = []  # compact mapping per file\n",
    "\n",
    "for i, (p, nsegs) in enumerate(zip(good_files, seg_counts), 1):\n",
    "    x = load_and_clean(p)\n",
    "    segs = segment_signal(x, SR, SEG_SEC, HOP_SEC)\n",
    "\n",
    "    start = write_pos\n",
    "    for k, seg in enumerate(segs):\n",
    "        feat = mfcc_features(seg)  # float32\n",
    "        X_mm[write_pos] = feat.astype(OUT_DTYPE, copy=False)\n",
    "        write_pos += 1\n",
    "\n",
    "    index.append({\n",
    "        \"file\": str(p),\n",
    "        \"start\": int(start),\n",
    "        \"n_segments\": int(len(segs))\n",
    "    })\n",
    "\n",
    "    if i % 100 == 0 or i == len(good_files):\n",
    "        print(f\"Pass2: {i}/{len(good_files)} | written segments={write_pos}/{total_segments}\")\n",
    "\n",
    "# Flush to disk\n",
    "del X_mm\n",
    "\n",
    "print(\"\\nDone writing:\", OUT_X)\n",
    "print(\"Total written:\", write_pos, \"Expected:\", total_segments)\n",
    "if write_pos != total_segments:\n",
    "    print(\"WARNING: written != expected. Something changed between passes.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3db2500",
   "metadata": {},
   "source": [
    "# Cell 7 — Save index + metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b2dd14d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved index: C:\\Users\\leona\\Documents\\Thesis_Project_UACH\\Temp\\Dataset\\features_mfcc_unlabeled\\unlabeled_index.json\n",
      "Saved meta: C:\\Users\\leona\\Documents\\Thesis_Project_UACH\\Temp\\Dataset\\features_mfcc_unlabeled\\meta_unlabeled.json\n"
     ]
    }
   ],
   "source": [
    "with open(OUT_INDEX, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(index, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "meta = {\n",
    "    \"data_dir\": str(DATA_DIR),\n",
    "    \"csv_path\": str(CSV_PATH),\n",
    "    \"excluded_labeled_count\": int(len(labeled_names)),\n",
    "    \"unlabeled_requested\": int(len(unlabeled_paths)),\n",
    "    \"unlabeled_processed_good\": int(len(good_files)),\n",
    "    \"unlabeled_failed\": int(len(failed)),\n",
    "    \"total_segments\": int(total_segments),\n",
    "    \"feature_shape_per_segment\": [int(C), int(H), int(W)],\n",
    "    \"dtype\": str(OUT_DTYPE),\n",
    "    \"sr\": SR,\n",
    "    \"trim_db\": TRIM_DB,\n",
    "    \"seg_sec\": SEG_SEC,\n",
    "    \"hop_sec\": HOP_SEC,\n",
    "    \"n_mfcc\": N_MFCC,\n",
    "    \"add_deltas\": ADD_DELTAS,\n",
    "    \"n_fft\": int(N_FFT),\n",
    "    \"hop_len\": int(HOP_LEN),\n",
    "    \"fmin\": int(FMIN),\n",
    "    \"fmax\": int(FMAX),\n",
    "}\n",
    "\n",
    "with open(OUT_META, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(meta, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(\"Saved index:\", OUT_INDEX)\n",
    "print(\"Saved meta:\", OUT_META)\n",
    "\n",
    "if failed:\n",
    "    print(\"\\nSome files failed. First 3:\")\n",
    "    for item in failed[:3]:\n",
    "        print(item[\"file\"])\n",
    "        print(\"  \", item[\"error\"][:200])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f2fc097",
   "metadata": {},
   "source": [
    "# Cell 8 — Quick sanity load (memmap) + shape check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aa179b25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded X_unlabeled: (687350, 3, 32, 201) float16\n"
     ]
    }
   ],
   "source": [
    "X_unl = np.load(OUT_X, mmap_mode=\"r\")\n",
    "print(\"Loaded X_unlabeled:\", X_unl.shape, X_unl.dtype)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
