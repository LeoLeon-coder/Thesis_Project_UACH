{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Beehive Audio → NumPy Feature Builder\n",
        "**Works with flat folders of WAVs** (all mixed) and **optionally** a CSV for labels.\n",
        "Default features: **log-Mel**. You can switch to MFCC later."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# !pip install librosa soundfile scipy scikit-learn numpy pandas\n",
        "import os\n",
        "from pathlib import Path\n",
        "import json\n",
        "import random\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import librosa\n",
        "import soundfile as sf\n",
        "from scipy.signal import butter, sosfiltfilt\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Configuration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# --- Paths (Windows friendly) ---\n",
        "# Set to your flat WAV folder:\n",
        "DATA_DIR = Path(r\"C:\\Users\\leona\\Documents\\Thesis_Project_UACH\\Temp\\Dataset\\BeesAnna\\sound_files\")\n",
        "\n",
        "# Output directory (you can change this):\n",
        "OUT_DIR  = Path(r\"C:\\Users\\leona\\Documents\\Thesis_Project_UACH\\Temp\\Dataset\\BeesAnna\\features_bees\")\n",
        "\n",
        "# Optional: provide a CSV with columns: filename,label\n",
        "# 'filename' should match the WAV file name in DATA_DIR (or a relative path).\n",
        "# Example labels: queen, no_queen (strings). The notebook will map them to integers.\n",
        "LABELS_CSV = None  # e.g., Path(r\"C:\\path\\to\\labels.csv\")\n",
        "\n",
        "# If LABELS_CSV is None, we'll export a single unlabeled X_all.npy and files.npy\n",
        "\n",
        "# --- Audio & preprocessing ---\n",
        "SR        = 16000\n",
        "TRIM_DB   = 30\n",
        "USE_BANDPASS = True\n",
        "BP_LOW, BP_HIGH = 100, 1000  # Hz\n",
        "\n",
        "# --- Segmentation ---\n",
        "SEG_SEC   = 2.0\n",
        "HOP_SEC   = 1.0\n",
        "\n",
        "# --- Feature Type ---\n",
        "FEATURE_TYPE = \"logmel\"  # \"logmel\" or \"mfcc\"\n",
        "\n",
        "# Log-Mel parameters\n",
        "N_MELS    = 64\n",
        "N_FFT     = int(0.025 * SR)  # 25 ms\n",
        "HOP_LEN   = int(0.010 * SR)  # 10 ms\n",
        "FMIN, FMAX = 20, SR // 2\n",
        "\n",
        "# MFCC parameters\n",
        "N_MFCC      = 32\n",
        "ADD_DELTAS  = True           # stack Δ and ΔΔ for CNN channels\n",
        "\n",
        "# --- Splits & randomness (used only if labels CSV is provided) ---\n",
        "RANDOM_SEED = 123\n",
        "TEST_SIZE   = 0.15\n",
        "VAL_SIZE    = 0.15           # of remaining after test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Utilities"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "def peak_normalize(x, eps=1e-9):\n",
        "    peak = np.max(np.abs(x)) + eps\n",
        "    return x / peak\n",
        "\n",
        "def bandpass_sos(sr, low_hz, high_hz, order=4):\n",
        "    return butter(order, [low_hz, high_hz], btype='bandpass', fs=sr, output='sos')\n",
        "\n",
        "def apply_bandpass(x, sr, low, high):\n",
        "    sos = bandpass_sos(sr, low, high)\n",
        "    return sosfiltfilt(sos, x)\n",
        "\n",
        "def load_and_clean(path):\n",
        "    x, _sr = librosa.load(path, sr=SR, mono=True)\n",
        "    x, _ = librosa.effects.trim(x, top_db=TRIM_DB)\n",
        "    x = peak_normalize(x)\n",
        "    if USE_BANDPASS:\n",
        "        x = apply_bandpass(x, SR, BP_LOW, BP_HIGH)\n",
        "    return x\n",
        "\n",
        "def segment_signal(x, sr, seg_sec, hop_sec):\n",
        "    seg_len = int(seg_sec * sr)\n",
        "    hop_len = int(hop_sec * sr)\n",
        "    if len(x) < seg_len:\n",
        "        pad = seg_len - len(x)\n",
        "        x = np.pad(x, (0, pad), mode='reflect')\n",
        "    segments = []\n",
        "    for start in range(0, max(1, len(x)-seg_len+1), hop_len):\n",
        "        end = start + seg_len\n",
        "        seg = x[start:end]\n",
        "        if len(seg) < seg_len:\n",
        "            seg = np.pad(seg, (0, seg_len - len(seg)), mode='reflect')\n",
        "        segments.append(seg)\n",
        "    return segments\n",
        "\n",
        "def compute_logmel(seg):\n",
        "    S = librosa.feature.melspectrogram(\n",
        "        y=seg, sr=SR, n_fft=N_FFT, hop_length=HOP_LEN,\n",
        "        n_mels=N_MELS, fmin=FMIN, fmax=FMAX, power=2.0\n",
        "    )\n",
        "    logS = librosa.power_to_db(S, ref=np.max)\n",
        "    return logS[np.newaxis, :, :].astype(np.float32)\n",
        "\n",
        "def compute_mfcc(seg):\n",
        "    mfcc = librosa.feature.mfcc(\n",
        "        y=seg, sr=SR, n_mfcc=N_MFCC, n_fft=N_FFT, hop_length=HOP_LEN,\n",
        "        fmin=FMIN, fmax=FMAX\n",
        "    )\n",
        "    if ADD_DELTAS:\n",
        "        delta = librosa.feature.delta(mfcc)\n",
        "        delta2 = librosa.feature.delta(mfcc, order=2)\n",
        "        feat = np.stack([mfcc, delta, delta2], axis=0)\n",
        "    else:\n",
        "        feat = mfcc[np.newaxis, :, :]\n",
        "    return feat.astype(np.float32)\n",
        "\n",
        "def featurize(seg):\n",
        "    return compute_logmel(seg) if FEATURE_TYPE == \"logmel\" else compute_mfcc(seg)\n",
        "\n",
        "def standardize_features(train_X, val_X, test_X, eps=1e-6):\n",
        "    C = train_X.shape[1]\n",
        "    means, stds = [], []\n",
        "    train_X_std = train_X.copy(); val_X_std = val_X.copy(); test_X_std = test_X.copy()\n",
        "    for c in range(C):\n",
        "        mu = train_X[:, c].mean()\n",
        "        sigma = train_X[:, c].std() + eps\n",
        "        means.append(float(mu)); stds.append(float(sigma))\n",
        "        train_X_std[:, c] = (train_X[:, c] - mu) / sigma\n",
        "        val_X_std[:, c]   = (val_X[:, c]   - mu) / sigma\n",
        "        test_X_std[:, c]  = (test_X[:, c]  - mu) / sigma\n",
        "    stats = {\"channel_means\": means, \"channel_stds\": stds}\n",
        "    return train_X_std, val_X_std, test_X_std, stats"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Discover WAV files in a flat folder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "wav_paths = sorted(list(DATA_DIR.rglob(\"*.wav\"))) + sorted(list(DATA_DIR.rglob(\"*.WAV\")))\n",
        "print(f\"Found {len(wav_paths)} wav files under {DATA_DIR}\")\n",
        "if len(wav_paths) == 0:\n",
        "    raise SystemExit(f\"No WAV files found under {DATA_DIR}. Check the path and file extensions.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Optional: load labels from CSV"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "labels_df = None\n",
        "if LABELS_CSV is not None:\n",
        "    labels_df = pd.read_csv(LABELS_CSV)\n",
        "    assert {\"filename\",\"label\"}.issubset(labels_df.columns), \"CSV must have columns: filename,label\"\n",
        "    labels_df[\"filename\"] = labels_df[\"filename\"].astype(str)\n",
        "    fn2lab = dict(zip(labels_df[\"filename\"].map(lambda s: Path(s).name), labels_df[\"label\"].astype(str)))\n",
        "    y_labels = []\n",
        "    missing = []\n",
        "    for p in wav_paths:\n",
        "        bn = p.name\n",
        "        if bn in fn2lab:\n",
        "            y_labels.append(fn2lab[bn])\n",
        "        else:\n",
        "            missing.append(bn)\n",
        "    if missing:\n",
        "        print(f\"Warning: {len(missing)} files missing labels in CSV; they will be dropped.\")\n",
        "        keep_mask = [p.name in fn2lab for p in wav_paths]\n",
        "        wav_paths = [p for p, k in zip(wav_paths, keep_mask) if k]\n",
        "        y_labels  = [fn2lab[p.name] for p in wav_paths]\n",
        "    classes = sorted(set(y_labels))\n",
        "    lab2idx = {lab:i for i,lab in enumerate(classes)}\n",
        "    y_all = np.array([lab2idx[l] for l in y_labels], dtype=np.int64)\n",
        "    print(\"Classes -> indices:\", lab2idx)\n",
        "else:\n",
        "    print(\"No LABELS_CSV provided: proceeding with unlabeled export.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Build features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "random.seed(RANDOM_SEED); np.random.seed(RANDOM_SEED)\n",
        "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "def process_many(paths):\n",
        "    feats = []\n",
        "    for path in paths:\n",
        "        x = load_and_clean(str(path))\n",
        "        segments = segment_signal(x, SR, SEG_SEC, HOP_SEC)\n",
        "        for seg in segments:\n",
        "            feats.append(featurize(seg))\n",
        "    X = np.stack(feats, axis=0)  # (N,C,H,W)\n",
        "    return X\n",
        "\n",
        "if 'labels_df' in globals() and labels_df is not None:\n",
        "    # Labeled mode\n",
        "    wavs = np.array(wav_paths); y_all = np.array(y_all)\n",
        "    wavs_train, wavs_tmp, y_train, y_tmp = train_test_split(\n",
        "        wavs, y_all, test_size=TEST_SIZE, random_state=RANDOM_SEED, stratify=y_all\n",
        "    )\n",
        "    val_ratio_of_remaining = VAL_SIZE / (1.0 - TEST_SIZE)\n",
        "    wavs_val, wavs_test, y_val, y_test = train_test_split(\n",
        "        wavs_tmp, y_tmp, test_size=1.0 - val_ratio_of_remaining,\n",
        "        random_state=RANDOM_SEED, stratify=y_tmp\n",
        "    )\n",
        "\n",
        "    def process_many_labeled(paths, labels):\n",
        "        feats = []; labs = []\n",
        "        for path, lab in zip(paths, labels):\n",
        "            x = load_and_clean(str(path))\n",
        "            segments = segment_signal(x, SR, SEG_SEC, HOP_SEC)\n",
        "            for seg in segments:\n",
        "                feats.append(featurize(seg)); labs.append(lab)\n",
        "        X = np.stack(feats, axis=0); y = np.array(labs, dtype=np.int64)\n",
        "        return X, y\n",
        "\n",
        "    print(\"Processing TRAIN...\"); X_train, y_train = process_many_labeled(wavs_train, y_train)\n",
        "    print(\"Processing VAL...\");   X_val,   y_val   = process_many_labeled(wavs_val,   y_val)\n",
        "    print(\"Processing TEST...\");  X_test,  y_test  = process_many_labeled(wavs_test,  y_test)\n",
        "\n",
        "    print(\"Standardizing (train stats only)...\")\n",
        "    X_train, X_val, X_test, stats = standardize_features(X_train, X_val, X_test)\n",
        "\n",
        "    np.save(OUT_DIR / \"X_train.npy\", X_train); np.save(OUT_DIR / \"y_train.npy\", y_train)\n",
        "    np.save(OUT_DIR / \"X_val.npy\",   X_val);   np.save(OUT_DIR / \"y_val.npy\",   y_val)\n",
        "    np.save(OUT_DIR / \"X_test.npy\",  X_test);  np.save(OUT_DIR / \"y_test.npy\",  y_test)\n",
        "\n",
        "    with open(OUT_DIR / \"meta.json\", \"w\") as f:\n",
        "        json.dump({\n",
        "            \"sr\": SR,\n",
        "            \"segment_seconds\": SEG_SEC,\n",
        "            \"hop_seconds\": HOP_SEC,\n",
        "            \"feature_type\": FEATURE_TYPE,\n",
        "            \"n_mels\": int(N_MELS) if FEATURE_TYPE==\"logmel\" else None,\n",
        "            \"n_mfcc\": int(N_MFCC) if FEATURE_TYPE==\"mfcc\" else None,\n",
        "            \"add_deltas\": bool(ADD_DELTAS) if FEATURE_TYPE==\"mfcc\" else None,\n",
        "            \"classes\": {int(i): lab for lab, i in lab2idx.items()},  # inverse map\n",
        "            \"standardization\": stats,\n",
        "            \"bandpass\": {\"enabled\": bool(USE_BANDPASS), \"low\": int(BP_LOW), \"high\": int(BP_HIGH)}\n",
        "        }, f, indent=2)\n",
        "    print(\"Saved labeled splits to:\", OUT_DIR.resolve())\n",
        "else:\n",
        "    # Unlabeled mode\n",
        "    X_all = process_many(wav_paths)\n",
        "    np.save(OUT_DIR / \"X_all.npy\", X_all)\n",
        "    with open(OUT_DIR / \"files.json\", \"w\") as f:\n",
        "        json.dump([str(p) for p in wav_paths], f, indent=2)\n",
        "    with open(OUT_DIR / \"meta.json\", \"w\") as f:\n",
        "        json.dump({\n",
        "            \"sr\": SR,\n",
        "            \"segment_seconds\": SEG_SEC,\n",
        "            \"hop_seconds\": HOP_SEC,\n",
        "            \"feature_type\": FEATURE_TYPE,\n",
        "            \"n_mels\": int(N_MELS) if FEATURE_TYPE==\"logmel\" else None,\n",
        "            \"n_mfcc\": int(N_MFCC) if FEATURE_TYPE==\"mfcc\" else None,\n",
        "            \"add_deltas\": bool(ADD_DELTAS) if FEATURE_TYPE==\"mfcc\" else None,\n",
        "            \"bandpass\": {\"enabled\": bool(USE_BANDPASS), \"low\": int(BP_LOW), \"high\": int(BP_HIGH)}\n",
        "        }, f, indent=2)\n",
        "    print(\"Saved unlabeled features to:\", OUT_DIR.resolve())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Sanity check"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "if (OUT_DIR / \"X_all.npy\").exists():\n",
        "    Xa = np.load(OUT_DIR / \"X_all.npy\")\n",
        "    print(\"X_all shape:\", Xa.shape, \"(N, C, H, W)\")\n",
        "else:\n",
        "    Xt = np.load(OUT_DIR / \"X_train.npy\"); yt = np.load(OUT_DIR / \"y_train.npy\")\n",
        "    print(\"X_train shape:\", Xt.shape, \" y_train:\", yt.shape)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "pygments_lexer": "ipython3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}